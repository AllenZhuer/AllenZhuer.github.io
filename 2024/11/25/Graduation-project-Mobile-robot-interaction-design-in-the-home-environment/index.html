<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Allearn">
    
    <title>
        
            Bridging Technology and Everyday Life, Building a Home Environment Reception Robot |
        
        Allen&#39;s blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/dahuai.svg">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/css/font-awesome.min.css">
    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"example.com","root":"/","language":"en","path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"/images/dahuai.svg","favicon":"/images/dahuai.svg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":true,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"Two roads diverged in a wood, and I took the one less traveled by, And that has made all the difference."},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":false},"lazyload":{"enable":true},"version":"3.4.3"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                Allen&#39;s blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/tags"
                            >
                                TAGS
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/links"
                            >
                                LINKS
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >
                                ABOUT
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/tags">TAGS</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/links">LINKS</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about">ABOUT</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">Bridging Technology and Everyday Life, Building a Home Environment Reception Robot</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/dahuai.svg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Allearn</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;2024-11-25 10:29:14
    </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/Robotics/">Robotics</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/HCI/">HCI</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
    
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>In an era where artificial intelligence and robotics are reshaping industries, the promise of home robots stands out as a beacon of innovation. Imagine a robot that can assist with household chores, recognize family members, engage in meaningful conversations, and adapt to dynamic environments. This vision inspired my graduation thesis, where I designed and implemented a mobile robot system tailored to interact seamlessly within a home environment. </p>
<p>A few years later, I learned that my project and work were used as teaching materials and the foundation for the teams from the School of Automation, Southeast University, to participate in the RoboCup@Home China. I’m very proud that my work can contribute to the competition. This also means my desire to dive deep into Human-Computer Interaction to combine cutting-edge technologies and business to create inspired products and services that solve customers’ problems.</p>
<blockquote>
<p>This is a list of the current desired technical abilities that the tests in RoboCup@Home will focus on.</p>
<ul>
<li>Navigation in dynamic environments </li>
<li>Fast and easy calibration and setup: The ultimate goal is to have a robot up and running out of the box</li>
<li>Object recognition </li>
<li>Object manipulation </li>
<li>Detection and Recognition of Humans </li>
<li>Natural human-robot interaction </li>
<li>Speech recognition </li>
<li>Gesture recognition </li>
<li>Robot applications RoboCup@Home is aiming for applications of robots in daily life.</li>
</ul>
</blockquote>
<p>This project aims to develop highly relevant service and assistive robot technology for future personal domestic applications. The focus lies on the following domains but is not limited to: Human-Robot Interaction and Cooperation, Navigation and Mapping in home environments, Computer Vision and Object Recognition under natural light conditions, Object Manipulation, Adaptive Behaviors, Standardization, and System Integration.</p>
<h1 id="Core-Functions"><a href="#Core-Functions" class="headerlink" title="Core Functions"></a>Core Functions</h1><h2 id="Scenario-Welcoming-Friends-at-Home-with-the-Robot-Assistant"><a href="#Scenario-Welcoming-Friends-at-Home-with-the-Robot-Assistant" class="headerlink" title="Scenario: Welcoming Friends at Home with the Robot Assistant"></a>Scenario: Welcoming Friends at Home with the Robot Assistant</h2><p>It’s a quiet afternoon at home, and you’ve invited a couple of friends over to relax and catch up. Just as you hear the doorbell ring, your robot assistant springs to life, ready to help create a seamless and welcoming experience.</p>
<h3 id="Step-1-Greeting-the-Guests"><a href="#Step-1-Greeting-the-Guests" class="headerlink" title="Step 1:  Greeting the Guests"></a>Step 1:  Greeting the Guests</h3><p>As your first friend steps into the house, the robot assistant moves forward to greet them. Its camera focuses on their face, and it says warmly:<br><em>“Hello, welcome! May I know your name?”</em><br>Your friend replies, “I’m Alex.” The robot repeats their name to confirm and then adds:<br><em>“It’s great to meet you, Alex. May I ask, what’s your favorite drink?”</em><br>Alex responds with a smile, “I love Cola.” The robot confirms their choice and saves their details, associating the name and drink preference with their face.</p>
<p>When your second friend arrives, the robot repeats the same process, efficiently recognizing and recording their name and drink preference as well.</p>
<p>If one of your friends is a frequent visitor, the robot has already  recognized them instantly then will greet them with personalized messages like:<br><em>“Welcome back, Alex! Would you like the usual Cola today?”</em> </p>
<h3 id="Step-2-Guiding-the-Guests-to-the-Living-Room"><a href="#Step-2-Guiding-the-Guests-to-the-Living-Room" class="headerlink" title="Step 2: Guiding the Guests to the Living Room"></a>Step 2: Guiding the Guests to the Living Room</h3><p>Once both friends are inside, the robot gestures and says:<br><em>“Please follow me, and I’ll guide you to your seats.”</em><br>It smoothly navigates through the house, leading your friends to the living room. It identifies the unoccupied seats and gestures politely:<br><em>“Here are two comfortable seats for you. Please, have a seat.”</em></p>
<h3 id="Step-3-Personalized-Drink-Delivery"><a href="#Step-3-Personalized-Drink-Delivery" class="headerlink" title="Step 3: Personalized Drink Delivery"></a>Step 3: Personalized Drink Delivery</h3><p>After your friends are seated, the robot turns to you for a moment and confirms:<br><em>“Would you like me to prepare the drinks for Alex and Jamie?”</em><br>You nod, and the robot replies, <em>“Understood. Please relax while I handle it.”</em></p>
<p>The robot moves to the kitchen, identifies the correct drinks, and carefully retrieves them. It returns to the living room and delivers the drinks to each guest by name:<br><em>“Alex, here’s your Cola. Jamie, here’s your favorite soda. Enjoy!”</em></p>
<p>Even if the robot can’t physically pick up the drinks, it uses a clear gesture or light indicator to direct your guests to their beverages, ensuring a thoughtful touch.</p>
<h3 id="Step-4-Creating-a-Relaxed-Atmosphere"><a href="#Step-4-Creating-a-Relaxed-Atmosphere" class="headerlink" title="Step 4: Creating a Relaxed Atmosphere"></a>Step 4: <strong>Creating a Relaxed Atmosphere</strong></h3><p>As the conversation flows, the robot subtly monitors the interaction, staying on standby in case anyone needs assistance. Its graphical user interface, displayed on a nearby screen, shows a friendly message such as:<br><em>“Let me know if you need anything else!”</em></p>
<p>If your friends move around, the robot adjusts and remains responsive, making sure they feel at home.</p>
<h2 id="Product-Function-and-Modules"><a href="#Product-Function-and-Modules" class="headerlink" title="Product Function and Modules"></a>Product Function and Modules</h2><p>The product’s core functionalities include the following five aspects:</p>
<ol>
<li><strong>Visitor Identification Based on Visual Recognition</strong>: Assuming there are two visitors, each arrives and pauses in front of the robot upon entry. The robot’s camera detects and captures their faces, automatically recognizes them, and saves the visitors’ facial images.</li>
<li><strong>Voice-Based Greeting Function</strong>: After detecting the visitor’s face, the robot provides a voice greeting and asks for the visitor’s name. It confirms the name by repetition and records it. The robot then asks for the visitor’s favorite beverage, confirms it, and records the information. Both the name and the preferred beverage are linked to the facial image, with the image file named after the visitor’s name.</li>
<li><strong>Seating Guidance Function</strong>: The robot directs the guest to an unoccupied seat. It issues a voice prompt, “Please follow me,” and leads the guest to the available spot, arranging for them to sit.</li>
<li><strong>Beverage Delivery Function</strong>: After the guest is seated, the robot moves to the beverage station, picks up the guest’s preferred drink (represented by an empty bottle if necessary), and delivers it to the correct guest. (If the grasping function is not feasible, the robot can instead point to the beverage.)</li>
<li><strong>Graphical User Interface Control</strong>: A graphical user interface is implemented to control the entire process.</li>
</ol>
<h4 id="Additional-Potential-Enhancements"><a href="#Additional-Potential-Enhancements" class="headerlink" title="Additional Potential Enhancements:"></a>Additional Potential Enhancements:</h4><ul>
<li>Adding object recognition to enable functionalities like object grasping and delivery.</li>
</ul>
<p>To meet the basic requirements, the product requires at least five functional modules: a camera detection module, a microphone acquisition module, a path planning module, a trajectory optimization module, and an arms control module. The correspondence between functions and modules is shown in <strong>Table 1</strong>.</p>
<h3 id="Table-1-Functions-and-Modules"><a href="#Table-1-Functions-and-Modules" class="headerlink" title="Table 1:  Functions and Modules"></a>Table 1:  Functions and Modules</h3><table>
<thead>
<tr>
<th>Function</th>
<th>Camera Detection Module</th>
<th>Microphone Acquisition Module</th>
<th>Path Planning Module</th>
<th>Trajectory Optimization Module</th>
<th>Arm Control Module</th>
</tr>
</thead>
<tbody><tr>
<td>Visitor identification based on face recognition</td>
<td>✓</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Voice-based greeting function</td>
<td></td>
<td>✓</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Seating guidance function</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td></td>
</tr>
<tr>
<td>Beverage delivery and identification</td>
<td>✓</td>
<td></td>
<td></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>Graphical interface control</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
</tbody></table>
<h1 id="Design-and-Methodology"><a href="#Design-and-Methodology" class="headerlink" title="Design and Methodology"></a>Design and Methodology</h1><h2 id="System-Overview"><a href="#System-Overview" class="headerlink" title="System Overview"></a>System Overview</h2><p>The system is built on a Turtlebot platform, enhanced with a HOKUYO URG-04LX-UG01 laser radar and an RGB-D camera for advanced functionality. Facial detection and recognition use MTCNN and FaceNet models, trained and fine-tuned on NVIDIA 2080Ti GPUs or Google Colab.</p>
<h4 id="Development-Environment"><a href="#Development-Environment" class="headerlink" title="Development Environment"></a><strong>Development Environment</strong></h4><ul>
<li><strong>OS</strong>: Ubuntu 16.04</li>
<li><strong>Frameworks</strong>: ROS for Turtlebot development, CUDA 9.0, and TensorFlow 1.7 for model training.</li>
</ul>
<h4 id="Final-Deployment"><a href="#Final-Deployment" class="headerlink" title="Final Deployment"></a><strong>Final Deployment</strong></h4><p>The fully developed system was successfully implemented on the MORO dual-arm robot, seamlessly integrating navigation, facial recognition, and robotic control. Since the MORO platform was still at the very beginning stage then, the grasp tasks were replaced by pointing to the drinks, and the KUKA LBR IIWA robot arm and RGBD camera realized the grasp tasks. </p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://allenzhuer.github.io/picx-images-hosting/image.8ojr4t0mou.webp"
                      alt="MORO II robot"
                ></p>
<h2 id="Visitor-identification"><a href="#Visitor-identification" class="headerlink" title="Visitor identification"></a>Visitor identification</h2><p>The visitor identification task module primarily uses an <strong>RGB-D camera</strong> to actively capture images for face detection and recognition. The goal is to identify whether a detected face is new or already stored in the system database and transition seamlessly to the inquiry task once a face is recognized.</p>
<h4 id="Process-Flow"><a href="#Process-Flow" class="headerlink" title="Process Flow"></a><strong>Process Flow</strong></h4><ol>
<li><p><strong>Initialization</strong>:</p>
<ul>
<li>The robot begins in a stationary position at the door.</li>
<li>The <strong>camera thread</strong> is activated to continuously capture frames.</li>
</ul>
</li>
<li><p><strong>Face Detection</strong>:</p>
<ul>
<li>Each frame is analyzed for face detection with a time limit of <strong>3 seconds</strong> per detection attempt.</li>
<li>If no face is detected within 3 seconds, the robot performs <strong>small rotational movements</strong> to expand its field of view and continues detecting.</li>
</ul>
</li>
<li><p><strong>Recognition and Database Check</strong>:</p>
<ul>
<li>If a face is detected:<ul>
<li>The system marks this recognition task as successful.</li>
<li>It checks the database for the detected face:<ul>
<li>If the face is new, the calculated facial feature data is extracted and stored in the database.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Failure Handling</strong>:</p>
<ul>
<li><p>If no face is detected after </p>
<p>3 seconds of rotation</p>
<p>, the system:</p>
<ul>
<li>Confirms whether any face was found during the current session.</li>
<li>If no face was found:<ul>
<li>All threads are stopped, and the robot pauses operations for 3 seconds before restarting the recognition task.</li>
</ul>
</li>
<li>If a face <strong>was found</strong>, the recognition task concludes, and the system transitions to the <strong>inquiry task</strong>.</li>
</ul>
</li>
</ul>
<p>(The chart is genrated by ChatGPT.)</p>
</li>
</ol>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://allenzhuer.github.io/picx-images-hosting/Face_recognition.2kryc1wfy6.svg"
                      alt="Visitor identification"
                ></p>
<p>Face Recognition will be introduced in a new blog for the learning path in <a class="link"   target="_blank" rel="noopener" href="https://allenzhuer.github.io/2024/12/14/Face-Recognition/" >Face Recognition<i class="fas fa-external-link-alt"></i></a>. </p>
<h2 id="Voice-based-greeting-function"><a href="#Voice-based-greeting-function" class="headerlink" title="Voice-based greeting function"></a>Voice-based greeting function</h2><p>The IFLYTEK voice transcription realizes a voice-based greeting function to obtain voice information, which will be stored in the database with face information and personal information. (I have not learned NLP then, so have to turn to open-source tech or tools for help.)</p>
<p>The inquiry task module leverages a <strong>microphone array</strong>, an <strong>RGB-D camera</strong>, and a <strong>speech output module</strong> to interact with household members and collect their preferences. For example, the robot might ask, <em>“What’s your favorite drink?”</em> Upon receiving a response, it converts the speech to text, detects keywords (e.g., Sprite, Coke, milk tea), and stores the data for future use.</p>
<p><strong>Process Flow</strong></p>
<ol>
<li><strong>Module Initialization</strong>:<ul>
<li>Start the <strong>RGB-D camera thread</strong> and <strong>microphone array thread</strong>.</li>
<li>Rotate the camera to search for faces.</li>
</ul>
</li>
<li><strong>Face Detection</strong>:<ul>
<li>Once a single face is detected, the camera aligns to keep the face centered.</li>
</ul>
</li>
<li><strong>Interactive Questioning</strong>:<ul>
<li>The robot asks: <em>“What’s your name?”</em> Processes and saves the name.</li>
<li>Then asks: <em>“What’s your favorite drink?”</em> Transcribes the response and extracts key preferences.</li>
</ul>
</li>
<li><strong>Data Storage</strong>:<ul>
<li>The system links the detected face with the name and preferences.</li>
<li>Packages the data into a structured record in the database.</li>
</ul>
</li>
<li><strong>Repeating the Process</strong>:<ul>
<li>After one member’s information is collected, the system checks for other undetected faces.</li>
<li>If faces remain, the camera rotates to locate another person and repeats the inquiry process.</li>
</ul>
</li>
<li><strong>Task Completion</strong>:<ul>
<li>When all faces have been detected and information collected, the module concludes the inquiry task and transitions to the <strong>guidance task</strong>.</li>
</ul>
</li>
</ol>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://allenzhuer.github.io/picx-images-hosting/image.6wqrjom36d.webp"
                      alt="Voice-based greeting function"
                > </p>
<p>(The chart is genrated by ChatGPT.)</p>
<h2 id="Guidance-function"><a href="#Guidance-function" class="headerlink" title="Guidance function"></a>Guidance function</h2><p>The primary functionalities required for this task include <strong>Marker search and recognition</strong>, <strong>motion planning</strong>, and <strong>obstacle avoidance</strong>. Each function works in harmony to ensure the robot can execute tasks efficiently and safely. The markers are used for turtlebot, and it can be replaced by pre-programming in Moro robot system to guide to the pre-defined places. </p>
<p>You can visit the blog regrading to the Motion planning and Obstacle avoidance to learn the specific algorithms.  <em><strong>TODO: Motion planning blog links.</strong></em></p>
<h4 id="Process-flow"><a href="#Process-flow" class="headerlink" title="Process flow"></a><strong>Process flow</strong></h4><ol>
<li>The robot initializes the task by scanning for the first marker to determine its starting point.</li>
<li>Upon detecting a marker:<ul>
<li>The marker’s information is decoded to determine the next action.</li>
<li>The robot plans its route to the specified target area.</li>
</ul>
</li>
<li>During navigation:<ul>
<li>Obstacles are detected and avoided using real-time LiDAR data.</li>
<li>The robot updates its path dynamically to ensure smooth movement.</li>
</ul>
</li>
<li>If the robot reaches the final marker, it concludes the task or transitions to a new task as per the marker’s instructions.</li>
</ol>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://allenzhuer.github.io/picx-images-hosting/image.60ua4ckstu.webp"
                      alt="Guidance function"
                ></p>
<h2 id="Grasp-Function"><a href="#Grasp-Function" class="headerlink" title="Grasp Function"></a>Grasp Function</h2><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://allenzhuer.github.io/picx-images-hosting/image.3yei67cre4.webp"
                      alt="image"
                ></p>
<h1 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h1><h2 id="Face-Recognition"><a href="#Face-Recognition" class="headerlink" title="Face Recognition"></a>Face Recognition</h2><p><strong>Face Recognition with LFW Dataset and MTCNN</strong></p>
<ol>
<li><p><strong>MTCNN Training on LFW Dataset</strong></p>
<ul>
<li>The LFW dataset was used to train MTCNN for face detection.</li>
<li>The dataset was divided into 80% for training and 20% for testing and validation, along with a custom-built face dataset.</li>
<li>The final detection accuracy was 96.4%.</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://allenzhuer.github.io/picx-images-hosting/image.5fkn84dj1a.webp"
                      alt="MTCNN Examples"
                ></p>
</li>
<li><p><strong>FaceNet Training with Processed Images</strong></p>
<ul>
<li>All images in the LFW dataset were resized to 160×160 pixels using MTCNN preprocessing.</li>
<li>The processed images were then fed into the FaceNet model for training.</li>
<li>The trained FaceNet model achieved a recognition accuracy of 98.5%.</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://allenzhuer.github.io/picx-images-hosting/image.9rjgfnx42u.webp"
                      alt="FaceNet examples"
                ></p>
</li>
<li><p><strong>Challenges in Recognition Accuracy</strong></p>
<ul>
<li>Misrecognitions occurred in two primary scenarios:<br>a. When an image contained two or more faces, the target face might not be selected.<br>b. Poor lighting, occlusions, or unfavorable angles reduced the confidence score of the target face compared to others.</li>
</ul>
</li>
<li><p><strong>Example of MTCNN Misrecognition</strong></p>
<ul>
<li>In one example, the male face had a confidence score of 0.78, while the female face had a score of 0.85.</li>
<li>The target was the male face, but due to occlusion, MTCNN detected and cropped the female face instead.</li>
<li>As a result, the male face was excluded.</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://allenzhuer.github.io/picx-images-hosting/image.5tr2yznm48.webp"
                      alt="MTCNN Misrecognition example"
                ></p>
</li>
</ol>
<p><strong>Conclusion:</strong><br>MTCNN and FaceNet demonstrate high accuracy for face detection and recognition. However, challenges like multiple faces, occlusions, and lighting variations can lead to misrecognitions, indicating areas for further improvement.</p>
<h2 id="Voice-Greating-Function"><a href="#Voice-Greating-Function" class="headerlink" title="Voice Greating Function"></a>Voice Greating Function</h2><p><strong>Inquiry Module</strong></p>
<p>The inquiry module primarily utilizes the <strong>iFlytek speech-to-text API</strong>. This API allows for the transcription of a local <code>.wav</code> audio file into text. For example, a local file named <code>input.wav</code> can be transcribed into text such as, <em>“我是猪八戒，我喜欢喝可乐”</em> (translated: “I am Zhu Bajie, and I like drinking cola”). An example of this process is shown in the following Figures.</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://allenzhuer.github.io/picx-images-hosting/image.6wqs9vobth.webp"
                      alt="image"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://allenzhuer.github.io/picx-images-hosting/image.1ovhmvvw4a.webp"
                      alt="image"
                ></p>
<p>The two images above illustrate the process of recording audio for family members and saving it locally as the <code>input.wav</code> audio file. The workflow is as follows:</p>
<ol>
<li><strong>Audio Recording</strong>: Family members’ voices are recorded and saved as a <code>.wav</code> file (e.g., <code>input.wav</code>).</li>
<li><strong>Speech Transcription</strong>: The audio file is transcribed into text using the iFlytek API.</li>
<li><strong>Keyword Extraction</strong>: Keywords, such as names and preferences, are extracted from the transcribed text and saved locally in the <code>mine.txt</code> file.</li>
<li><strong>Image Naming</strong>: Collected facial images are linked to the corresponding names from the transcribed data and renamed accordingly.</li>
</ol>
<p>This integrated approach ensures that each family member’s face and preferences are organized systematically for further use.</p>
<h2 id="The-whole-process"><a href="#The-whole-process" class="headerlink" title="The whole process"></a>The whole process</h2><p>To evaluate the overall effectiveness of integrating all components, the following images illustrate the testing process for the entire task workflow:</p>
<ol>
<li><p><strong>Face Detection and Recognition</strong>:<br>As shown in <strong>Figure (a)</strong>, when the target person enters the robot’s field of view, the robot captures images from the video feed via its camera. The system then performs face detection and recognition, extracting the facial information of the person and storing it in a local database. Once the facial information is obtained, the system issues a command to change the task state and transitions to the voice interaction module.</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://allenzhuer.github.io/picx-images-hosting/image.2rv6xrwxl3.webp"
                      alt="Figure a"
                ></p>
</li>
<li><p><strong>Voice Interaction</strong>:<br>In <strong>Figure (b)</strong>, the microphone prompts the target individual with a question: “Hello, what is your name?” The person responds, and the system attempts to recognize the spoken name. If the name is not accurately recognized, the system either repeats the question or confirms the name by ensuring that the same name is detected twice consecutively. If there is a mismatch, the system continues to ask until two consistent results are obtained. After obtaining the name, the system proceeds to inquire about the person’s favorite beverage. This process is similar to the name inquiry, and the results are displayed in <strong>Figure (c)</strong>.</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://allenzhuer.github.io/picx-images-hosting/image.1ap1w0tddq.webp"
                      alt="Figure b"
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://allenzhuer.github.io/picx-images-hosting/image.1ap1w0tddq.webp"
                      alt="Figure c"
                ></p>
</li>
<li><p><strong>Saving Information to the Database</strong>:<br>Once all information is collected, the system saves it in the database. As shown in <strong>Figure (f)</strong>, the database includes details such as the member’s ID, name, age, preferences, and facial data. The collected facial images are named according to the person’s name and saved locally.</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://allenzhuer.github.io/picx-images-hosting/image.2yyet7ldqq.webp"
                      alt="Figre f"
                ></p>
</li>
<li><p><strong>Proposing Personalized Tasks</strong>:<br>After completing the inquiries, the robot addresses the person by their name and makes a proposal, such as: “Wang Dapeng, would you like a cup of milk tea?” This question is formatted as: “Target name, would you like a cup of [favorite beverage]?” An example of this interaction is shown in <strong>Figure (d)</strong></p>
</li>
</ol>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://allenzhuer.github.io/picx-images-hosting/image.73u05bhlfx.webp"
                      alt="Figure d"
                ></p>
<ol start="5">
<li><p><strong>Re-encountering a Recognized Member</strong>:<br>When a previously recognized member reappears in the robot’s field of view, such as after registering “Wang Dapeng” and later encountering another person “Liu Tao,” the system logs their information as new. However, when “Wang Dapeng” appears again, the system recognizes them as an existing member and generates an “old” message to indicate prior recognition. The system then repeats the personalized interaction, as it did during the first encounter, by asking: “Wang Dapeng, would you like a cup of milk tea?” The result of this process is shown in <strong>Figure (e)</strong>.</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://allenzhuer.github.io/picx-images-hosting/image.67xipv8ldf.webp"
                      alt="Figure e"
                ></p>
</li>
</ol>
<h1 id="Improvements"><a href="#Improvements" class="headerlink" title="Improvements"></a>Improvements</h1><p>As described above, this paper presents the design of a simple home service robot system that performs several tasks. However, there are still many limitations for home service robots, which can be summarized as follows:</p>
<ol>
<li><strong>Communication Delays</strong>:<br>The communication delay between the face recognition and voice recognition modules is relatively long. In the future, the adoption of <strong>5G transmission</strong> could significantly improve the speed of data transfer, especially when dealing with large datasets.</li>
<li><strong>Misidentification in Multi-Face Scenarios</strong>:<br>When multiple faces appear in the robot’s field of view, the system may misidentify the target face. Future improvements in algorithms, such as the adoption of <strong>3D face recognition</strong>, could greatly enhance the accuracy of identification.</li>
<li><strong>Limited System Functionality</strong>:<br>The system designed in this study is relatively simple and performs only basic, single-purpose tasks. It is not yet suitable for complex home environments. In the future, home service robots will likely become <strong>smarter and more versatile</strong>, capable of completing a wide range of tasks quickly and efficiently.</li>
</ol>

        </div>

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2024/12/12/The-road-to-Navigation/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">The road to Navigation</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/2023/09/12/How-to-Analyze-DeFi-Projects/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">How to Analyze DeFi Projects</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2021</span>
              -
            
            2025&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Allearn</a>
        </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.3</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Core-Functions"><span class="nav-number">2.</span> <span class="nav-text">Core Functions</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Scenario-Welcoming-Friends-at-Home-with-the-Robot-Assistant"><span class="nav-number">2.1.</span> <span class="nav-text">Scenario: Welcoming Friends at Home with the Robot Assistant</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Step-1-Greeting-the-Guests"><span class="nav-number">2.1.1.</span> <span class="nav-text">Step 1:  Greeting the Guests</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Step-2-Guiding-the-Guests-to-the-Living-Room"><span class="nav-number">2.1.2.</span> <span class="nav-text">Step 2: Guiding the Guests to the Living Room</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Step-3-Personalized-Drink-Delivery"><span class="nav-number">2.1.3.</span> <span class="nav-text">Step 3: Personalized Drink Delivery</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Step-4-Creating-a-Relaxed-Atmosphere"><span class="nav-number">2.1.4.</span> <span class="nav-text">Step 4: Creating a Relaxed Atmosphere</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Product-Function-and-Modules"><span class="nav-number">2.2.</span> <span class="nav-text">Product Function and Modules</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Additional-Potential-Enhancements"><span class="nav-number">2.2.0.1.</span> <span class="nav-text">Additional Potential Enhancements:</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Table-1-Functions-and-Modules"><span class="nav-number">2.2.1.</span> <span class="nav-text">Table 1:  Functions and Modules</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Design-and-Methodology"><span class="nav-number">3.</span> <span class="nav-text">Design and Methodology</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#System-Overview"><span class="nav-number">3.1.</span> <span class="nav-text">System Overview</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Development-Environment"><span class="nav-number">3.1.0.1.</span> <span class="nav-text">Development Environment</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Final-Deployment"><span class="nav-number">3.1.0.2.</span> <span class="nav-text">Final Deployment</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Visitor-identification"><span class="nav-number">3.2.</span> <span class="nav-text">Visitor identification</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Process-Flow"><span class="nav-number">3.2.0.1.</span> <span class="nav-text">Process Flow</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Voice-based-greeting-function"><span class="nav-number">3.3.</span> <span class="nav-text">Voice-based greeting function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Guidance-function"><span class="nav-number">3.4.</span> <span class="nav-text">Guidance function</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Process-flow"><span class="nav-number">3.4.0.1.</span> <span class="nav-text">Process flow</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Grasp-Function"><span class="nav-number">3.5.</span> <span class="nav-text">Grasp Function</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Result"><span class="nav-number">4.</span> <span class="nav-text">Result</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Face-Recognition"><span class="nav-number">4.1.</span> <span class="nav-text">Face Recognition</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Voice-Greating-Function"><span class="nav-number">4.2.</span> <span class="nav-text">Voice Greating Function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#The-whole-process"><span class="nav-number">4.3.</span> <span class="nav-text">The whole process</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Improvements"><span class="nav-number">5.</span> <span class="nav-text">Improvements</span></a></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>



<script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/dark-light-toggle.js"></script>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/local-search.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/code-copy.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/lazyload.js"></script>


<div class="post-scripts">
    
        <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/left-side-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/libs/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/toc.js"></script>
    
</div>



</body>
</html>
